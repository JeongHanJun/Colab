{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Keras Functional API.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOC2nR0dZTOAAiVv1f4j6It",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JeongHanJun/Colab/blob/master/Keras_Functional_API.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAA-TMThQIML"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1nDMXqDQYcU"
      },
      "source": [
        "'''\n",
        "    Input -> 784 (28x28) dimentional vectors\n",
        "    \n",
        "    Dense -> 64 units / relu activation\n",
        "    Dense -> 64 units / relu activation\n",
        "    Dense -> 10 units / softmax activation\n",
        "\n",
        "    Output -> logits of a probability distribution over 10 classes\n",
        "'''\n",
        "inputs = keras.Input(shape = (784,))\n",
        "\n",
        "img_inputs = keras.Input(shape = (32, 32, 3))\n",
        "inputs.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWV7fR2iRWTh"
      },
      "source": [
        "inputs.dtype"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SY-1gqwqRYkk"
      },
      "source": [
        "dense = layers.Dense(64, activation = 'relu')\n",
        "x = dense(inputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nazi1YaESL-p"
      },
      "source": [
        "x = layers.Dense(64, activation = 'relu')(x)\n",
        "outputs = layers.Dense(10)(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nF0X8YlCSXja"
      },
      "source": [
        "models = keras.Model(inputs = inputs, outputs = outputs, name = \"mnist_data\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JkEZ88xDSeqK"
      },
      "source": [
        "models.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ja1dUPupSl0-"
      },
      "source": [
        "keras.utils.plot_model(models, 'my_first_model.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNEPkZGTS1TK"
      },
      "source": [
        "keras.utils.plot_model(models, 'my_first_model_with_shape_info.png', show_shapes = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xH4eoxvETJp0"
      },
      "source": [
        "# 트트 테테\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "x_train = x_train.reshape(60000, 784).astype('float32') / 255\n",
        "x_test = x_test.reshape(10000, 784).astype('float32') / 255\n",
        "\n",
        "models.compile(\n",
        "    loss = keras.losses.SparseCategoricalCrossentropy(from_logits = True),\n",
        "    optimizer = keras.optimizers.RMSprop(),\n",
        "    metrics = ['accuracy'],\n",
        ")\n",
        "\n",
        "history = models.fit(x_train, y_train, batch_size = 64, epochs = 2, validation_split = 0.2)\n",
        "\n",
        "test_scores = models.evaluate(x_test, y_test, verbose = 2)\n",
        "print('Test loss = ', test_scores[0])\n",
        "print('Test accuracy = ', test_scores[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUIwcaf-UeAs"
      },
      "source": [
        "models.save('path_to_my_model')\n",
        "del models\n",
        "my_model = keras.models.load_model('path_to_my_model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIUzP_NUVpUz"
      },
      "source": [
        "encoder_input = keras.Input(shape = (28, 28, 1), name = 'img')\n",
        "\n",
        "L1 = layers.Conv2D(16, 3, activation = 'relu')(encoder_input)\n",
        "L2 = layers.Conv2D(32, 3, activation = 'relu')(L1)\n",
        "L3 = layers.MaxPooling2D(3)(L2)\n",
        "\n",
        "L4 = layers.Conv2D(32, 3, activation = 'relu')(L3)\n",
        "L5 = layers.Conv2D(16, 3, activation = 'relu')(L4)\n",
        "\n",
        "encoder_output = layers.GlobalMaxPooling2D()(L5)\n",
        "\n",
        "encoder = keras.Model(encoder_input, encoder_output, name = 'encoder')\n",
        "encoder.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NeSv0yjrXQv7"
      },
      "source": [
        "L1 = layers.Reshape( (4, 4, 1) )(encoder_output)\n",
        "L2 = layers.Conv2DTranspose(16, 3, activation = 'relu')(L1)\n",
        "L3 = layers.Conv2DTranspose(32, 3, activation = 'relu')(L2)\n",
        "\n",
        "L4 = layers.UpSampling2D(3)(L3)\n",
        "L5 = layers.Conv2DTranspose(16, 3, activation = 'relu')(L4)\n",
        "\n",
        "decoder_output = layers.Conv2DTranspose(1, 3, activation = 'relu')(L5)\n",
        "\n",
        "autoencoder = keras.Model(encoder_input, decoder_output, name = 'autoencoder')\n",
        "autoencoder.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpf3teqNYPOq"
      },
      "source": [
        "encoder_input = keras.Input(shape = (28, 28, 1), name = 'original_img')\n",
        "x = layers.Conv2D(16, 3, activation=\"relu\")(encoder_input)\n",
        "x = layers.Conv2D(32, 3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(3)(x)\n",
        "x = layers.Conv2D(32, 3, activation=\"relu\")(x)\n",
        "x = layers.Conv2D(16, 3, activation=\"relu\")(x)\n",
        "encoder_output = layers.GlobalMaxPooling2D()(x)\n",
        "\n",
        "encoder = keras.Model(encoder_input, encoder_output, name=\"encoder\")\n",
        "encoder.summary()\n",
        "\n",
        "decoder_input = keras.Input(shape=(16,), name=\"encoded_img\")\n",
        "x = layers.Reshape((4, 4, 1))(decoder_input)\n",
        "x = layers.Conv2DTranspose(16, 3, activation=\"relu\")(x)\n",
        "x = layers.Conv2DTranspose(32, 3, activation=\"relu\")(x)\n",
        "x = layers.UpSampling2D(3)(x)\n",
        "x = layers.Conv2DTranspose(16, 3, activation=\"relu\")(x)\n",
        "decoder_output = layers.Conv2DTranspose(1, 3, activation=\"relu\")(x)\n",
        "\n",
        "decoder = keras.Model(decoder_input, decoder_output, name=\"decoder\")\n",
        "decoder.summary()\n",
        "\n",
        "autoencoder_input = keras.Input(shape=(28, 28, 1), name=\"img\")\n",
        "encoded_img = encoder(autoencoder_input)\n",
        "decoded_img = decoder(encoded_img)\n",
        "autoencoder = keras.Model(autoencoder_input, decoded_img, name=\"autoencoder\")\n",
        "autoencoder.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2EulnEywRxB"
      },
      "source": [
        "def get_model():\n",
        "    inputs = keras.Input(shape = (128,))\n",
        "    outputs = layers.Dense(1)(inputs)\n",
        "    return keras.Model(inputs, outputs)\n",
        "\n",
        "model1 = get_model()\n",
        "model2 = get_model()\n",
        "model3 = get_model()\n",
        "\n",
        "inputs = keras.Input(shape = (128, ))\n",
        "y1 = model1(inputs)\n",
        "y2 = model1(inputs)\n",
        "y3 = model1(inputs)\n",
        "outputs = layers.average([y1, y2, y3])\n",
        "ensemble_model = keras.Model(inputs = inputs, outputs = outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WcpBLWkdw6wg"
      },
      "source": [
        "## Multiple Input / Output Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbBzZKraxJO6"
      },
      "source": [
        "* 고객의 티켓을 발급할때, 우선순위를 지정하고, 올바른 부서로 라우팅해주는 시스템의 모델을 만든다고 가정\n",
        "\n",
        "- 모델에 필요한 입력 3가지\n",
        "    1. 티켓 제목( text input )\n",
        "    2. 티켓의 텍스트 본문( text input )\n",
        "    3. 사용자가 추가한 모든 태그( Category input )\n",
        "\n",
        "- 모델의 출력 2가지\n",
        "    1. 0과 1 사이의 우선순위 점수( 스칼라 시그모이드 출력)\n",
        "    2. 티켓을 처리해야 하는 부서(부서 집합에 대한 softmax 출력)\n",
        "\n",
        "위에 대한 내용을 Functional API를 통해 모델을 빌드한다면 아래와 같다\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8AXUo6ppxzmM"
      },
      "source": [
        "tags = 12\n",
        "words = 10000\n",
        "departments = 4\n",
        "\n",
        "title_input = keras.Input(\n",
        "    shape = (None, ), name = 'title'\n",
        ")\n",
        "body_input = keras.Input(shape = (None, ), name = 'body')\n",
        "tags_input = keras.Input(\n",
        "    shape = (tags, ),\n",
        "    name = 'tag'\n",
        ")\n",
        "\n",
        "title_features = layers.Embedding(words, 64)(title_input)\n",
        "body_features = layers.Embedding(words, 64)(body_input)\n",
        "title_features = layers.LSTM(128)(title_features)\n",
        "body_features = layers.LSTM(32)(body_features)\n",
        "\n",
        "x = layers.concatenate( [title_features, body_features, tags_input])\n",
        "\n",
        "priority_pred = layers.Dense(1, name = 'priority')(x)\n",
        "department_pred = layers.Dense(departments, name = 'department')(x)\n",
        "\n",
        "model = keras.Model(\n",
        "    inputs = [title_input, body_input, tags_input],\n",
        "    outputs = [priority_pred, department_pred]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30vKG6vK2rf0"
      },
      "source": [
        "keras.utils.plot_model(model, 'multi_input_and_output_model.png', show_shapes = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EnWIuegd22PF"
      },
      "source": [
        "model.compile(\n",
        "    optimizer = keras.optimizers.RMSprop(1e-3),\n",
        "    loss = [\n",
        "            keras.losses.BinaryCrossentropy(from_logits = True),\n",
        "            keras.losses.CategoricalCrossentropy(from_logits = True)\n",
        "    ],\n",
        "    loss_weights = [1.0, 0.2]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ek-nLunH3Oy5"
      },
      "source": [
        "model.compile(\n",
        "    optimizer=keras.optimizers.RMSprop(1e-3),\n",
        "    loss={\n",
        "        \"priority\": keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "        \"department\": keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "    },\n",
        "    loss_weights={\"priority\": 1.0, \"department\": 0.2},\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNBaC19n3bbo"
      },
      "source": [
        "inputs = keras.Input(shape=(32, 32, 3), name=\"img\")\n",
        "x = layers.Conv2D(32, 3, activation=\"relu\")(inputs)\n",
        "x = layers.Conv2D(64, 3, activation=\"relu\")(x)\n",
        "block_1_output = layers.MaxPooling2D(3)(x)\n",
        "\n",
        "x = layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(block_1_output)\n",
        "x = layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(x)\n",
        "block_2_output = layers.add([x, block_1_output])\n",
        "\n",
        "x = layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(block_2_output)\n",
        "x = layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(x)\n",
        "block_3_output = layers.add([x, block_2_output])\n",
        "\n",
        "x = layers.Conv2D(64, 3, activation=\"relu\")(block_3_output)\n",
        "x = layers.GlobalAveragePooling2D()(x)\n",
        "x = layers.Dense(256, activation=\"relu\")(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(10)(x)\n",
        "\n",
        "model = keras.Model(inputs, outputs, name=\"toy_resnet\")\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpc4xKa64sm8"
      },
      "source": [
        "# 위의 모델 도식화\n",
        "keras.utils.plot_model(model, 'mini_ResNet.png', show_shapes = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NF1Y-yMX425I"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
        "\n",
        "x_train = x_train.astype(\"float32\") / 255.0\n",
        "x_test = x_test.astype(\"float32\") / 255.0\n",
        "y_train = keras.utils.to_categorical(y_train, 10)\n",
        "y_test = keras.utils.to_categorical(y_test, 10)\n",
        "\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.RMSprop(1e-3),\n",
        "    loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[\"acc\"],\n",
        ")\n",
        "model.fit(x_train[:1000], y_train[:1000], batch_size=64, epochs=1, validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFJTh50q48IR"
      },
      "source": [
        "## 공유 레이어\n",
        "- Functional API의 장점중 하나인 공유 레이어를 사용하는 모델\n",
        "- 동일한 모델에서 여러번 재사용되는 레이어 인스턴스이다.\n",
        "- 서로 다른 입력간에 정보를 공유할 수 있다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCzQbYde5RtQ"
      },
      "source": [
        "shared_embedding = layers.Embedding(1000, 128)\n",
        "\n",
        "text_input_a = keras.Input(shape=(None,), dtype=\"int32\")\n",
        "text_input_b = keras.Input(shape=(None,), dtype=\"int32\")\n",
        "\n",
        "encoded_input_a = shared_embedding(text_input_a)\n",
        "encoded_input_b = shared_embedding(text_input_b)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLBQ1cvt5bp2"
      },
      "source": [
        "## 레이어 그래프에서의 노드 추출 및 재사용\n",
        "- 계층의 그래프는 정적 데이터 구조이므로 액세스하고 검사할 수 있다.\n",
        "- 중간 레이어 ( 그래프의 Node )의 활성화에 엑세스 하여 다른 곳에서 재사용할 수 있음을 의미한다.\n",
        "- 아래는 ImageNet에서 사전 훈련된 가중치가 있는 VGG19모델을 통한 예시이다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9CoB-Z1A5yPT"
      },
      "source": [
        "vgg19 = tf.keras.applications.VGG19()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3C3Coka50_a"
      },
      "source": [
        "features_list = [layer.output for layer in vgg19.layers]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAz_0YVw56XL"
      },
      "source": [
        "feat_extraction_model = keras.Model(inputs = vgg19.input, outputs = features_list)\n",
        "\n",
        "img = np.random.random( (1, 224, 224, 3)).astype('float32')\n",
        "extracted_features = feat_extraction_model(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2tnOO-w6Hb0"
      },
      "source": [
        "# tensorflow.keras 안에 포함된 다양한 기본 제공 레이어들\n",
        "1. Convolution Layer\n",
        "    - Conv1D, Conv2D, Conv3D, Conv2DTranspose\n",
        "\n",
        "2. Pooling Layer\n",
        "    - MaxPooling1D, MaxPooling2D, MaxPooling3D, AveragePooling1D\n",
        "\n",
        "3. RNN Layer\n",
        "    - GRU, LSTM, ConvLSTM2D\n",
        "\n",
        "4. BatchNormalization, Dropout, Embedding, etc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SlROJG-O6rBv"
      },
      "source": [
        "다양한 내용들이 제공되는데, 만약 나에게 필요한 것을 찾지 못한다면?\n",
        "-> 고유한 레이어를 만들어 API를 확장하고, Layer 클래스를 하위 Layer클래스로 만들고 구현하면 된다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5W8nleZl67A0"
      },
      "source": [
        "# tensorflow.keras.layers.Dense 기본 구현"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKVrOnHN7Hh6"
      },
      "source": [
        "class CustomDense(layers.Layer):\n",
        "    def __init__(self, units = 32):\n",
        "        super(CustomDense, self).__init__()\n",
        "        self.units = units\n",
        "    \n",
        "    def build(self, input_shape):\n",
        "        self.w = self.add_weight(\n",
        "            shape = (input_shape[-1], self.units),\n",
        "            initializer = 'random_normal',\n",
        "            trainable = True\n",
        "        )\n",
        "        self.b = self.add_weight(\n",
        "            shape = (self.units, ), initializer = 'random_normal', trainable = True\n",
        "        )\n",
        "    \n",
        "    def call(self, inputs):\n",
        "        return tf.matmul(inputs, self.w) + self.b\n",
        "\n",
        "inputs = keras.Input( (4,) )\n",
        "outputs= CustomDense(10)(inputs)\n",
        "\n",
        "model = keras.Model(inputs, outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0r2A8WL7zSv"
      },
      "source": [
        "class CustomDense(layers.Layer):\n",
        "    def __init__(self, units=32):\n",
        "        super(CustomDense, self).__init__()\n",
        "        self.units = units\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.w = self.add_weight(\n",
        "            shape=(input_shape[-1], self.units),\n",
        "            initializer=\"random_normal\",\n",
        "            trainable=True,\n",
        "        )\n",
        "        self.b = self.add_weight(\n",
        "            shape=(self.units,), initializer=\"random_normal\", trainable=True\n",
        "        )\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return tf.matmul(inputs, self.w) + self.b\n",
        "    # get_config 메서드\n",
        "    # 사용자 지정 레이어의 직렬화는 지원, 레이어 인스턴스의 생성자 인수를 반환한다.\n",
        "    def get_config(self):\n",
        "        return {\"units\": self.units}\n",
        "\n",
        "\n",
        "inputs = keras.Input((4,))\n",
        "outputs = CustomDense(10)(inputs)\n",
        "\n",
        "model = keras.Model(inputs, outputs)\n",
        "config = model.get_config()\n",
        "\n",
        "new_model = keras.Model.from_config(config, custom_objects={\"CustomDense\": CustomDense})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnMNwYsy73jV"
      },
      "source": [
        "inputs = keras.Input(shape=(32,))\n",
        "x = layers.Dense(64, activation='relu')(inputs)\n",
        "outputs = layers.Dense(10)(x)\n",
        "mlp = keras.Model(inputs, outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDXNSJxx8MXV"
      },
      "source": [
        "class MLP(keras.Model):\n",
        "\n",
        "  def __init__(self, **kwargs):\n",
        "    super(MLP, self).__init__(**kwargs)\n",
        "    self.dense_1 = layers.Dense(64, activation='relu')\n",
        "    self.dense_2 = layers.Dense(10)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    x = self.dense_1(inputs)\n",
        "    return self.dense_2(x)\n",
        "\n",
        "# Instantiate the model.\n",
        "mlp = MLP()\n",
        "# Necessary to create the model's state.\n",
        "# The model doesn't have a state until it's called at least once.\n",
        "_ = mlp(tf.zeros((1, 32)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtztVIoZ8Ne8"
      },
      "source": [
        "units = 32\n",
        "timesteps = 10\n",
        "input_dim = 5\n",
        "\n",
        "# Define a Functional model\n",
        "inputs = keras.Input((None, units))\n",
        "x = layers.GlobalAveragePooling1D()(inputs)\n",
        "outputs = layers.Dense(1)(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "\n",
        "\n",
        "class CustomRNN(layers.Layer):\n",
        "    def __init__(self):\n",
        "        super(CustomRNN, self).__init__()\n",
        "        self.units = units\n",
        "        self.projection_1 = layers.Dense(units=units, activation=\"tanh\")\n",
        "        self.projection_2 = layers.Dense(units=units, activation=\"tanh\")\n",
        "        # Our previously-defined Functional model\n",
        "        self.classifier = model\n",
        "\n",
        "    def call(self, inputs):\n",
        "        outputs = []\n",
        "        state = tf.zeros(shape=(inputs.shape[0], self.units))\n",
        "        for t in range(inputs.shape[1]):\n",
        "            x = inputs[:, t, :]\n",
        "            h = self.projection_1(x)\n",
        "            y = h + self.projection_2(state)\n",
        "            state = y\n",
        "            outputs.append(y)\n",
        "        features = tf.stack(outputs, axis=1)\n",
        "        print(features.shape)\n",
        "        return self.classifier(features)\n",
        "\n",
        "\n",
        "rnn_model = CustomRNN()\n",
        "_ = rnn_model(tf.zeros((1, timesteps, input_dim)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2cM67Zb8TFc"
      },
      "source": [
        "units = 32\n",
        "timesteps = 10\n",
        "input_dim = 5\n",
        "batch_size = 16\n",
        "\n",
        "\n",
        "class CustomRNN(layers.Layer):\n",
        "    def __init__(self):\n",
        "        super(CustomRNN, self).__init__()\n",
        "        self.units = units\n",
        "        self.projection_1 = layers.Dense(units=units, activation=\"tanh\")\n",
        "        self.projection_2 = layers.Dense(units=units, activation=\"tanh\")\n",
        "        self.classifier = layers.Dense(1)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        outputs = []\n",
        "        state = tf.zeros(shape=(inputs.shape[0], self.units))\n",
        "        for t in range(inputs.shape[1]):\n",
        "            x = inputs[:, t, :]\n",
        "            h = self.projection_1(x)\n",
        "            y = h + self.projection_2(state)\n",
        "            state = y\n",
        "            outputs.append(y)\n",
        "        features = tf.stack(outputs, axis=1)\n",
        "        return self.classifier(features)\n",
        "\n",
        "\n",
        "# Note that you specify a static batch size for the inputs with the `batch_shape`\n",
        "# arg, because the inner computation of `CustomRNN` requires a static batch size\n",
        "# (when you create the `state` zeros tensor).\n",
        "inputs = keras.Input(batch_shape=(batch_size, timesteps, input_dim))\n",
        "x = layers.Conv1D(32, 3)(inputs)\n",
        "outputs = CustomRNN()(x)\n",
        "\n",
        "model = keras.Model(inputs, outputs)\n",
        "\n",
        "rnn_model = CustomRNN()\n",
        "_ = rnn_model(tf.zeros((1, 10, 5)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71bv4s2E8VxI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}