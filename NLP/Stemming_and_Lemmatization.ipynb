{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Stemming and Lemmatization.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYGnlHVtQ4iB"
      },
      "source": [
        "## Stemming(어간 추출) and Lemmatization(표제어 추출)\n",
        "+ 단어의 원형을 찾기 위해 사용\n",
        "+ ex) plays, played -> play\n",
        "\n",
        "### 1. Stemming (어간 추출)\n",
        "+ 단어에서 어간을 추출한다.\n",
        "+ 단어를 보고 어미를 잘라서 어근을 추출한다.\n",
        "+ NLTK 의 대표적인 Stemmer로는 Porter, Lancaster, Snowball Stemmer\n",
        "\n",
        "### 2. Lemmatization (표제어 추출)\n",
        "+ '품사'와 같은 문법적인 요소, 더 의미적인 부분을 감안한다.\n",
        "+ 장점은 일반적으로 Stemming 보다 더 정확하게 어근을 추출한다.\n",
        "+ 단점은 일반적으로 Stemming 보다 시간이 더 오래 걸린다.\n",
        "+ Lemmatization은 WordnetLemmatizer를 주로 사용한다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2mpqsDzeRD4g",
        "outputId": "33bbf9f1-1a87-4f4d-bc5a-0630eaef7382"
      },
      "source": [
        "# nltk library baseline\n",
        "import nltk\n",
        "nltk.download('stopwords')# for Stop word\n",
        "nltk.download('punkt')# for Tokenize\n",
        "nltk.download('wordnet')# for Lemmatization"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_UYGsyicSNG2"
      },
      "source": [
        "#### Porter Stemmer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WnZLHMNJSAMt",
        "outputId": "45a4c42f-678c-48fe-d884-39684ea307bf"
      },
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "print(stemmer.stem('working'),stemmer.stem('works'),stemmer.stem('worked'))\n",
        "print(stemmer.stem('amusing'),stemmer.stem('amuses'),stemmer.stem('amused'))\n",
        "print(stemmer.stem('happier'),stemmer.stem('happiest'))\n",
        "print(stemmer.stem('fancier'),stemmer.stem('fanciest'))\n",
        "print(stemmer.stem('was'), stemmer.stem('love'))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "work work work\n",
            "amus amus amus\n",
            "happier happiest\n",
            "fancier fanciest\n",
            "wa love\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6fB2_Z4SHWS"
      },
      "source": [
        "#### Lancaster Stemmer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O7uTYQgjSVWL",
        "outputId": "d0597b4a-0dfc-4791-e202-6023398375e4"
      },
      "source": [
        "from nltk.stem import LancasterStemmer\n",
        "stemmer = LancasterStemmer()\n",
        "\n",
        "print(stemmer.stem('working'),stemmer.stem('works'),stemmer.stem('worked'))\n",
        "print(stemmer.stem('amusing'),stemmer.stem('amuses'),stemmer.stem('amused'))\n",
        "print(stemmer.stem('happier'),stemmer.stem('happiest'))\n",
        "print(stemmer.stem('fancier'),stemmer.stem('fanciest'))\n",
        "print(stemmer.stem('was'), stemmer.stem('love'))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "work work work\n",
            "amus amus amus\n",
            "happy happiest\n",
            "fant fanciest\n",
            "was lov\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_W-pTMlSVoB"
      },
      "source": [
        "#### Porter vs Lancaster\n",
        "+ 기본적으로 둘다 잘 추출되었지만, 둘다 amuse 로 추출해야하는데 amus 로 추출함\n",
        "+ was love 가 추출되야 하는데 Porter는 wa love , Lancaster는 was lov 로 둘다 2%씩 부족함\n",
        "+ 결론적으로 둘이 서로 다른 성능을 보임"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUlkk5vkSoc3"
      },
      "source": [
        "#### Lemmatization (표제어 추출)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GriMqJ61SygW",
        "outputId": "8827d5e1-6b38-49d4-d871-629ab182bfad"
      },
      "source": [
        "# 이 부분을 실행하기 위해서는\n",
        "#nltk.download('wordnet')이 필요함.\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "lemma = WordNetLemmatizer()\n",
        "print(lemma.lemmatize('amusing'),lemma.lemmatize('amuses'),lemma.lemmatize('amused'))\n",
        "print(lemma.lemmatize('happier'),lemma.lemmatize('happiest'))\n",
        "print(lemma.lemmatize('fancier'),lemma.lemmatize('fanciest'))\n",
        "print(lemma.lemmatize('was'), lemma.lemmatize('love'))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "amusing amuses amused\n",
            "happier happiest\n",
            "fancier fanciest\n",
            "wa love\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKRgW3HbTQ8w"
      },
      "source": [
        "# 성능이 좋지 않다. Lemmatization은 품사 속성을 넣어줘야 더 잘 추출된다."
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jKa1EI3ZTyJ0",
        "outputId": "5ad7c61d-ea19-4441-c4a5-a0be44877cce"
      },
      "source": [
        "lemma = WordNetLemmatizer()\n",
        "print(lemma.lemmatize('amusing', 'v'),lemma.lemmatize('amuses', 'v'),lemma.lemmatize('amused', 'v'))\n",
        "print(lemma.lemmatize('happier', 'a'),lemma.lemmatize('happiest', 'a'))\n",
        "print(lemma.lemmatize('fancier', 'a'),lemma.lemmatize('fanciest', 'a'))\n",
        "print(lemma.lemmatize('was', 'v'), lemma.lemmatize('love', 'v'))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "amuse amuse amuse\n",
            "happy happy\n",
            "fancy fancy\n",
            "be love\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2DqabYJT6nd"
      },
      "source": [
        "# Successfully extracted"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}