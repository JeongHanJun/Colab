{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "서브클래싱을 통한 레이어 및 모델 개발.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMsDLZgt9Au9cNVeq5unAPe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JeongHanJun/Colab/blob/master/%EC%84%9C%EB%B8%8C%ED%81%B4%EB%9E%98%EC%8B%B1%EC%9D%84_%ED%86%B5%ED%95%9C_%EB%A0%88%EC%9D%B4%EC%96%B4_%EB%B0%8F_%EB%AA%A8%EB%8D%B8_%EA%B0%9C%EB%B0%9C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oiuKbX9mA8yv"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WqsDCdXcBBDY"
      },
      "source": [
        "# 서브클래싱을 통한 새 모델 / 레이어를 만드는 과정"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JT5Lk_YoBMZQ"
      },
      "source": [
        "## Layer class = combination of weight + computation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_66oDyjCF1M"
      },
      "source": [
        "class Linear(keras.layers.Layer):\n",
        "  def __init__(self, units = 32, input_dim = 32):\n",
        "    super(Linear, self).__init__()\n",
        "    w_init = tf.random_normal_initializer()\n",
        "    self.w = tf.Variable(\n",
        "        initial_value = w_init(shape = (input_dim, units), dtype = 'float32'),\n",
        "        trainable = True\n",
        "    )\n",
        "    b_init = tf.zeros_initializer()\n",
        "    self.b = tf.Variable(\n",
        "        initial_value = b_init(shape = (units, ), dtype = 'float32'),\n",
        "        trainable = True\n",
        "    )\n",
        "  def call(self, inputs):\n",
        "    return tf.matmul(inputs, self.w) + self.b"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMxA_3xiC8rw"
      },
      "source": [
        "#### w = weight 가중치 , b = bias 편향"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8RN-SmjODBpT",
        "outputId": "de3755bb-752a-4cda-8fd0-8a7858e2388c"
      },
      "source": [
        "x = tf.ones( (2, 2) )\n",
        "linear_layer = Linear(4, 2)\n",
        "y = linear_layer(x)\n",
        "print(y)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[-0.00268681  0.08147862 -0.04045039  0.04046633]\n",
            " [-0.00268681  0.08147862 -0.04045039  0.04046633]], shape=(2, 4), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNTQGV36DJto"
      },
      "source": [
        "assert linear_layer.weights == [linear_layer.w , linear_layer.b]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LcGFpKqCE-48",
        "outputId": "8cfbee28-ba40-436f-ee90-616cb2f6db16"
      },
      "source": [
        "class Linear(keras.layers.Layer):\n",
        "  def __init__(self, units = 32, input_dim = 32):\n",
        "    super(Linear, self).__init__()\n",
        "    self.w = self.add_weight(\n",
        "        shape = (input_dim, units), \n",
        "        initializer = 'random_normal',\n",
        "        trainable = True\n",
        "    )\n",
        "    self.b = self.add_weight(\n",
        "        shape = (units, ) ,\n",
        "        initializer = 'zeros',\n",
        "        trainable = True,\n",
        "                             )\n",
        "  def call(self, inputs):\n",
        "    return tf.matmul(inputs, self.w) + self.b\n",
        "\n",
        "x = tf.ones( (2, 2) )\n",
        "linear_layer = Linear(4, 2)\n",
        "y = linear_layer(x)\n",
        "print(y)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[-0.01950542 -0.00725076  0.03661449  0.11594519]\n",
            " [-0.01950542 -0.00725076  0.03661449  0.11594519]], shape=(2, 4), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SzZyIyNqFt6m",
        "outputId": "543b580b-e295-495a-eaa8-6f8a30c1a7ce"
      },
      "source": [
        "class ComputeSum(keras.layers.Layer):\n",
        "  def __init__(self, input_dim):\n",
        "    super(ComputeSum, self).__init__()\n",
        "    self.total =tf.Variable(initial_value = tf.zeros((input_dim, )), trainable = False)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    self.total.assign_add(tf.reduce_sum(inputs, axis = 0))\n",
        "    return self.total\n",
        "\n",
        "x = tf.ones( (2, 2) )\n",
        "my_sum = ComputeSum(2)\n",
        "y = my_sum(x)\n",
        "print(y.numpy())\n",
        "y = my_sum(x)\n",
        "print(y.numpy())"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2. 2.]\n",
            "[4. 4.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pH1fc9OQNpuj",
        "outputId": "bb6f2673-8fd6-4928-c6da-a87a33428097"
      },
      "source": [
        "print(\"weights : \", len(my_sum.weights))\n",
        "print()\n",
        "print('non-trainable weights : ', len(my_sum.non_trainable_weights))\n",
        "print()\n",
        "print('trainable_weights : ', len(my_sum.trainable_weights))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "weights :  1\n",
            "\n",
            "non-trainable weights :  1\n",
            "\n",
            "trainable_weights :  0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JMMHyiOLQrNz"
      },
      "source": [
        "## Best practice : input의 shape가 알려질때까지 가중치 생성 연기 ( deferring weight creation until the shape of the inputs is known )"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KajofACRRV_W"
      },
      "source": [
        "class Linear(keras.layers.Layer):\n",
        "  def __init__(self, units = 32):\n",
        "    super(Linear, self).__init__()\n",
        "    self.units = units\n",
        "  \n",
        "  # create layer weight in the build method\n",
        "  def build(self, input_shape):\n",
        "    self.w = self.add_weight(\n",
        "        shape = (input_shape[-1], self.units),\n",
        "        initializer = 'random_normal',\n",
        "        trainable = True\n",
        "    )\n",
        "    self.b = self.add_weight(\n",
        "        shape = (self.units,), initializer = 'random_normal', trainable = True\n",
        "    )\n",
        "  \n",
        "  def call(self, inputs):\n",
        "    return tf.matmul(inputs, self.w) + self.b\n",
        "\n",
        "linear_layer = Linear(32)\n",
        "y = linear_layer(x)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtP_56pKRt-p"
      },
      "source": [
        "## 레이어의 재귀적 구성\n",
        "- init 메소드에서 하위 레이어를 구성\n",
        "- 하위 레이어에는 일반적으로 빌드 메소드가 있으므로, 외부 레이어가 빌드될 때 같이 빌드된다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-4u2fqgTN07",
        "outputId": "542b98f1-da2f-435b-a086-255af0205b04"
      },
      "source": [
        "class MLPBlock(keras.layers.Layer):\n",
        "  def __init__(self):\n",
        "    super(MLPBlock, self).__init__()\n",
        "    self.linear_1 = Linear(32)\n",
        "    self.linear_2 = Linear(32)\n",
        "    self.linear_3 = Linear(1)\n",
        "  \n",
        "  def call(self, inputs):\n",
        "    x = self.linear_1(inputs)\n",
        "    x = tf.nn.relu(x)\n",
        "    x = self.linear_2(x)\n",
        "    x = tf.nn.relu(x)\n",
        "    return self.linear_3(x)\n",
        "\n",
        "mlp = MLPBlock()\n",
        "y = mlp(tf.ones(shape = (3, 64)))\n",
        "print('weights : ', len(mlp.weights))\n",
        "print('trainable weights : ', len(mlp.trainable_weights))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "weights :  6\n",
            "trainable weights :  6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UmcY7R8T6hf"
      },
      "source": [
        "## add_loss()\n",
        "- call() layer를 만들떄, 나중에 훈련 루프를 작성할떄 사용할 손실 텐서를 만들수 있다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9z5-NZpFVBI_"
      },
      "source": [
        "class ActivityRegularizationLayer(keras.layers.Layer):\n",
        "  def __init__(self, rate = 1e-2):\n",
        "    super(ActivityRegularizationLayer, self).__init__()\n",
        "    self.rate = rate\n",
        "  def call(self, inputs):\n",
        "    self.add_loss(self.rate * tf.reduce_sum(inputs))\n",
        "    return inputs"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2mUuWZOVSNx"
      },
      "source": [
        "class OuterLayer(keras.layers.Layer):\n",
        "  def __init__(self):\n",
        "    super(OuterLayer, self).__init__()\n",
        "    self.activity_reg = ActivityRegularizationLayer(1e-2)\n",
        "  \n",
        "  def call(self, inputs):\n",
        "    return self.activity_reg(inputs)\n",
        "\n",
        "layer = OuterLayer()\n",
        "assert len(layer.losses) == 0\n",
        "\n",
        "_ = layer(tf.zeros(1, 1))\n",
        "assert len(layer.losses) == 1\n",
        "\n",
        "_ = layer(tf.zeros(1, 1))\n",
        "assert len(layer.losses) == 1"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E2S-qS0OWnar",
        "outputId": "24ae9c26-1763-43ee-cd03-f456bb470d91"
      },
      "source": [
        "class OuterLayerWithKernelRegularizer(keras.layers.Layer):\n",
        "  def __init__(self):\n",
        "    super(OuterLayerWithKernelRegularizer, self).__init__()\n",
        "    self.dense = keras.layers.Dense(\n",
        "        32, kernel_regularizer = tf.keras.regularizers.l2(1e-3)\n",
        "    )\n",
        "  \n",
        "  def call(self, inputs):\n",
        "    return self.dense(inputs)\n",
        "  \n",
        "layer = OuterLayerWithKernelRegularizer()\n",
        "_ = layer(tf.zeros((1, 1)))\n",
        "print(layer.losses)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[<tf.Tensor: shape=(), dtype=float32, numpy=0.0019578154>]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AoqUqw1zY-tv"
      },
      "source": [
        "### 위와 같은 손실은 일반적인 훈련 루프( Model Training loop ) 작성시 고려해야 한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2RgPYoGoZmD_",
        "outputId": "15e0d79b-9945-480c-e6bb-26fadaa67ee2"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "inputs = keras.Input(shape=(3,))\n",
        "outputs = ActivityRegularizationLayer()(inputs)\n",
        "model = keras.Model(inputs, outputs)\n",
        "\n",
        "# If there is a loss passed in `compile`, the regularization\n",
        "# losses get added to it\n",
        "model.compile(optimizer=\"adam\", loss=\"mse\")\n",
        "model.fit(np.random.random((2, 3)), np.random.random((2, 3)))\n",
        "\n",
        "# It's also possible not to pass any loss in `compile`,\n",
        "# since the model already has a loss to minimize, via the `add_loss`\n",
        "# call during the forward pass!\n",
        "model.compile(optimizer=\"adam\")\n",
        "model.fit(np.random.random((2, 3)), np.random.random((2, 3)))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 137ms/step - loss: 0.1734\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0290\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb0eb9e1850>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17TvEPOea_yr"
      },
      "source": [
        "# Model Class\n",
        "- 일반적으로 layer클래스를 사용해, 내부의 계산 블록 모델을 정의하고, 클래스를 사용해서 학습할 외부 모델을 정의한다.\n",
        "- 유명한 ResNet50 모델에서는 여러 ResNet 블록을 서브클래싱 Layer하고 1개의 Model은 전체 ResNet50 네트워크를 포함한다.\n",
        "- 이 Model 클래스는 Layer의 다음 3개 차이점을 제외하고 동일한 API를 갖는다.\n",
        "  1. 기본 제공 교육, 평가 및 예측 루프 ( model.fit(), model.evaluate(), model.predict())를 보여준다.\n",
        "  2. model.layers 속성을 통해 내부 layer목록을 보여준다.\n",
        "  3. 저장 및 직렬화 API ( save(), save_weights() )를 보여준다.\n",
        "\n",
        "- Layer클래스는 계층 또는 블록으로 부르기도 한다.\n",
        "- Model 클래스는 모델 또는 네트워크로 부르기도 한다.\n",
        "- 아래는 기초적인 mnist resnet 예제를 통한 Model fit과 save_weights이다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "42m5ayzOmqIf",
        "outputId": "cffb1fef-6fd2-4f20-db16-5b1b549d6516"
      },
      "source": [
        "'''\n",
        "class ResNet(tf.keras.Model):\n",
        "\n",
        "  def __init__(self, num_classes = 1000):\n",
        "    super(ResNet, self).__init__()\n",
        "    self.block_1 = ResNetBlock()\n",
        "    self.block_2 = ResNetBlock()\n",
        "    self.global_pool = layers.GlobalAveragePooling2D()\n",
        "    self.classifier = Dense(num_classes)\n",
        "  \n",
        "  def call(self, inputs):\n",
        "    x = self.block_1(inputs)\n",
        "    x = self.block_2(x)\n",
        "    x = self.global_pool(x)\n",
        "    return self.classifier(x)\n",
        "\n",
        "resnet = ResNet()\n",
        "dataset = \n",
        "resnet.fit(dataset, epochs = 10)\n",
        "resnet.save(filepath)\n",
        "'''"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nclass ResNet(tf.keras.Model):\\n\\n  def __init__(self, num_classes = 1000):\\n    super(ResNet, self).__init__()\\n    self.block_1 = ResNetBlock()\\n    self.block_2 = ResNetBlock()\\n    self.global_pool = layers.GlobalAveragePooling2D()\\n    self.classifier = Dense(num_classes)\\n  \\n  def call(self, inputs):\\n    x = self.block_1(inputs)\\n    x = self.block_2(x)\\n    x = self.global_pool(x)\\n    return self.classifier(x)\\n\\nresnet = ResNet()\\ndataset = \\nresnet.fit(dataset, epochs = 10)\\nresnet.save(filepath)\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3B_kZwIXnK-E"
      },
      "source": [
        "# 종합적으로 VAE(Variational AutoEncoder) 구현\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "class Sampling(layers.Layer):\n",
        "\n",
        "  def call(self, inputs):\n",
        "    z_mean, z_log_var = inputs\n",
        "    batch = tf.shape(z_mean)[0]\n",
        "    dim = tf.shape(z_mean)[1]\n",
        "    epsilon = tf.keras.backend.random_normal(shape = (batch, dim))\n",
        "    return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
        "\n",
        "class Encoder(layers.Layer):\n",
        "\n",
        "  def __init__(self, latent_dim = 32, intermediate_dim = 64, name = 'encoder', **kwargs):\n",
        "    super(Encoder, self).__init__(name = name, **kwargs)\n",
        "    self.dense_proj = layers.Dense(intermediate_dim, activation = 'relu')\n",
        "    self.dense_mean = layers.Dense(latent_dim)\n",
        "    self.dense_log_var = layers.Dense(latent_dim)\n",
        "    self.sampling = Sampling()\n",
        "  \n",
        "  def call(self, inputs):\n",
        "    x = self.dense_proj(inputs)\n",
        "    z_mean = self.dense_mean(x)\n",
        "    z_log_var = self.dense_log_var(x)\n",
        "    z = self.sampling( (z_mean, z_log_var) )\n",
        "    return z_mean, z_log_var, z\n",
        "\n",
        "class Decoder(layers.Layer):\n",
        "\n",
        "  def __init__(self, original_dim, intermediate_dim = 64, name = 'decoder', **kwargs):\n",
        "    super(Decoder, self).__init__(name = name, **kwargs)\n",
        "    self.dense_proj = layers.Dense(intermediate_dim, activation = 'relu')\n",
        "    self.dense_output = layers.Dense(original_dim, activation = 'sigmoid')\n",
        "  \n",
        "  def call(self, inputs):\n",
        "    x = self.dense_proj(inputs)\n",
        "    return self.dense_output(x)\n",
        "  \n",
        "class VariationalAutoEncoder(keras.Model):\n",
        "\n",
        "  def __init__(\n",
        "      self,\n",
        "      original_dim,\n",
        "      intermediate_dim = 64,\n",
        "      latent_dim = 32,\n",
        "      name = 'autoencoder',\n",
        "      **kwargs):\n",
        "    super(VariationalAutoEncoder, self).__init__(name = name, **kwargs)\n",
        "    self.original_dim = original_dim\n",
        "    self.encoder = Encoder(latent_dim = latent_dim, intermediate_dim = intermediate_dim)\n",
        "    self.decoder = Decoder(original_dim, intermediate_dim = intermediate_dim)\n",
        "  \n",
        "  def call(self, inputs):\n",
        "    z_mean, z_log_var, z = self.encoder(inputs)\n",
        "    reconstructed = self.decoder(z)\n",
        "    kl_loss = -0.5 * tf.reduce_mean(\n",
        "      z_log_var - tf.square(z_mean) - tf.exp(z_log_var) + 1\n",
        "    )\n",
        "    self.add_loss(kl_loss)\n",
        "    return reconstructed\n",
        "    \n",
        "\n"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5kcqZAPwqCxf",
        "outputId": "f4396441-7185-4fbc-a1b3-4cdeb6539c04"
      },
      "source": [
        "# simple MNIST Train Loop\n",
        "original_dim = 784\n",
        "VAE = VariationalAutoEncoder(original_dim, 64, 32)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate = 1e-3)\n",
        "mse_loss = tf.keras.losses.MeanSquaredError()\n",
        "\n",
        "loss_metric = tf.keras.metrics.Mean()\n",
        "\n",
        "(x_train, _), _ = tf.keras.datasets.mnist.load_data()\n",
        "x_train = x_train.reshape(60000, 784).astype('float32') / 255\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(x_train)\n",
        "train_dataset = train_dataset.shuffle(buffer_size = 1024).batch(64)\n",
        "\n",
        "epochs = 3\n",
        "# Iterate over epochs\n",
        "for epoch in range(epochs):\n",
        "  print('start of epoch %d' %(epoch, ))\n",
        "\n",
        "  # Iterate over batches of the dataset\n",
        "  for step, x_batch_train in enumerate(train_dataset):\n",
        "    with tf.GradientTape() as tape:\n",
        "      reconstructed = VAE(x_batch_train)\n",
        "      loss = mse_loss(x_batch_train, reconstructed)\n",
        "      loss += sum(VAE.losses)\n",
        "    \n",
        "    grads = tape.gradient(loss, VAE.trainable_weights)\n",
        "    optimizer.apply_gradients(zip(grads, VAE.trainable_weights))\n",
        "\n",
        "    loss_metric(loss)\n",
        "\n",
        "    if step % 100 == 0:\n",
        "      print('step %d : mean loss = %.4f'%(step, loss_metric.result()))"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "start of epoch 0\n",
            "step 0 : mean loss = 0.3306\n",
            "step 100 : mean loss = 0.1256\n",
            "step 200 : mean loss = 0.0992\n",
            "step 300 : mean loss = 0.0892\n",
            "step 400 : mean loss = 0.0842\n",
            "step 500 : mean loss = 0.0808\n",
            "step 600 : mean loss = 0.0787\n",
            "step 700 : mean loss = 0.0771\n",
            "step 800 : mean loss = 0.0760\n",
            "step 900 : mean loss = 0.0749\n",
            "start of epoch 1\n",
            "step 0 : mean loss = 0.0747\n",
            "step 100 : mean loss = 0.0740\n",
            "step 200 : mean loss = 0.0735\n",
            "step 300 : mean loss = 0.0730\n",
            "step 400 : mean loss = 0.0727\n",
            "step 500 : mean loss = 0.0723\n",
            "step 600 : mean loss = 0.0720\n",
            "step 700 : mean loss = 0.0717\n",
            "step 800 : mean loss = 0.0715\n",
            "step 900 : mean loss = 0.0712\n",
            "start of epoch 2\n",
            "step 0 : mean loss = 0.0711\n",
            "step 100 : mean loss = 0.0710\n",
            "step 200 : mean loss = 0.0708\n",
            "step 300 : mean loss = 0.0707\n",
            "step 400 : mean loss = 0.0706\n",
            "step 500 : mean loss = 0.0704\n",
            "step 600 : mean loss = 0.0703\n",
            "step 700 : mean loss = 0.0702\n",
            "step 800 : mean loss = 0.0701\n",
            "step 900 : mean loss = 0.0700\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NRIAPhnDsCdp",
        "outputId": "664f1ed2-59be-43ed-a6a9-30da1e88b779"
      },
      "source": [
        "# VAE는 subclassing Model 이므로, 기본 제공 학습 루프가 있다.\n",
        "\n",
        "vae = VariationalAutoEncoder(784, 64, 32)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate = 1e-3)\n",
        "vae.compile(optimizer, loss = tf.keras.losses.MeanSquaredError())\n",
        "vae.fit(x_train, x_train, epochs = 2, batch_size = 64)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "938/938 [==============================] - 4s 3ms/step - loss: 0.0747\n",
            "Epoch 2/2\n",
            "938/938 [==============================] - 3s 3ms/step - loss: 0.0676\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb0ec266550>"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkfyqtZ1uipV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}