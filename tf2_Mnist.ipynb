{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tf2_Mnist.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMvghfdOK+goc0DgyoLoTwV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JeongHanJun/Colab/blob/master/tf2_Mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wN5CfJ0fn_rX",
        "outputId": "c8e7ba88-f302-445b-e276-3f97f30a212a"
      },
      "source": [
        "pip install tensorflow"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.5.0)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.36.2)\n",
            "Requirement already satisfied: grpcio~=1.34.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.34.1)\n",
            "Requirement already satisfied: tensorboard~=2.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.6.0,>=2.5.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.12.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.12.1)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.7.4.3)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.12)\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: keras-nightly~=2.5.0.dev in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.5.0.dev2021032900)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (1.32.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (57.2.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (1.8.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (0.4.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (3.3.4)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (4.2.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (4.7.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow) (4.6.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (2021.5.30)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow) (3.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.5->tensorflow) (3.5.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COuNJfjSoCL0"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "hesgdswaoTPs",
        "outputId": "90084262-7c13-4470-9efd-9264c3196745"
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.5.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WpngSFeoVg-"
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QK8vE_2EpYqW"
      },
      "source": [
        "## 1. Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gGKfLFACoabv",
        "outputId": "1736a228-fa07-4f0b-9a8d-f81e25f4a055"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.utils import to_categorical# one-hot encoding\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "print(tf.__version__)\n",
        "print(keras.__version__)\n"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.5.0\n",
            "2.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ss0F9h7eo3z0"
      },
      "source": [
        "## Hyper Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLEVWoXVpKMi"
      },
      "source": [
        "learning_rate = 0.01\n",
        "my_epochs = 15\n",
        "my_batch_size = 100"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLu2vHIQpm1-"
      },
      "source": [
        "## 3. Import MNIST data from keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CVuO6N9rpvp4",
        "outputId": "8d36312d-dd58-42e0-d373-29aca1c05b83"
      },
      "source": [
        "mnist = keras.datasets.mnist\n",
        "class_name = [ str(i) for i in range(10) ]\n",
        "print(class_name)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKtRD2hgqA_Y"
      },
      "source": [
        "#load data (train, test)\n",
        "(train_images, train_labels) , (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "# Normalize val <= 1 \n",
        "train_images = train_images.astype(np.float32) / 255.0\n",
        "test_images = test_images.astype(np.float32) / 255.0\n",
        "\n",
        "# ndim 차원 변경\n",
        "train_images = np.expand_dims(train_images, axis = -1)\n",
        "test_images = np.expand_dims(test_images, axis = -1)\n",
        "\n",
        "# label을 통한 one-hot encoding\n",
        "train_labels = to_categorical(train_labels, 10)\n",
        "test_labels = to_categorical(test_labels, 10)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rtujt8SrqRF"
      },
      "source": [
        "## 4. Model Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QB2dfQpwr95q"
      },
      "source": [
        "# Function Model Layer\n",
        "\n",
        "def create_model_relu():\n",
        "  inputs = keras.Input( shape = (28, 28, 1) )# keras.Input 에서 I가 소문자가 아닌 대문자 I\n",
        "  \n",
        "  conv1 = keras.layers.Conv2D( filters = 32, kernel_size = [3, 3], padding = \"SAME\", activation = tf.nn.relu )(inputs)# tf.nn.leaky_relu도 있음\n",
        "  pool1 = keras.layers.MaxPool2D( padding = \"SAME\" )(conv1)\n",
        "  \n",
        "  conv2 = keras.layers.Conv2D( filters = 64, kernel_size = [3, 3], padding = \"SAME\", activation = tf.nn.relu )(pool1)\n",
        "  pool2 = keras.layers.MaxPool2D( padding = \"SAME\" )(conv2)\n",
        "  \n",
        "  conv3 = keras.layers.Conv2D( filters = 128, kernel_size=[3, 3], padding = \"SAME\", activation=tf.nn.relu )(pool2)\n",
        "  pool3 = keras.layers.MaxPool2D( padding = \"SAME\" )(conv3)\n",
        "\n",
        "  pool3_flat = keras.layers.Flatten()(pool3)\n",
        "\n",
        "  dense4 = keras.layers.Dense( units = 256, activation = tf.nn.relu)(pool3_flat )\n",
        "  drop4 = keras.layers.Dropout( rate = 0.4 )(dense4)\n",
        "\n",
        "  logits = keras.layers.Dense(units = 10, activation = tf.nn.softmax)(drop4)\n",
        "\n",
        "  return keras.Model( inputs = inputs, outputs = logits )# inputs =inputs 에서 앞의 i는 소문자 i이고, parameter i 이다.  뒤의 I는 소문자 I이고 함수 상단 inputs = keras.Input으로 받은 Inputs이다.\n",
        "\n",
        "\n",
        "def create_model_leaky_relu():\n",
        "  inputs = keras.Input( shape = (28, 28, 1) )# keras.Input 에서 I가 소문자가 아닌 대문자 I\n",
        "  \n",
        "  conv1 = keras.layers.Conv2D( filters = 32, kernel_size = [3, 3], padding = \"SAME\", activation = tf.nn.leaky_relu )(inputs)\n",
        "  pool1 = keras.layers.MaxPool2D( padding = \"SAME\" )(conv1)\n",
        "  \n",
        "  conv2 = keras.layers.Conv2D( filters = 64, kernel_size = [3, 3], padding = \"SAME\", activation = tf.nn.leaky_relu )(pool1)\n",
        "  pool2 = keras.layers.MaxPool2D( padding = \"SAME\" )(conv2)\n",
        "  \n",
        "  conv3 = keras.layers.Conv2D( filters = 128, kernel_size=[3, 3], padding = \"SAME\", activation=tf.nn.leaky_relu )(pool2)\n",
        "  pool3 = keras.layers.MaxPool2D( padding = \"SAME\" )(conv3)\n",
        "\n",
        "  pool3_flat = keras.layers.Flatten()(pool3)\n",
        "\n",
        "  dense4 = keras.layers.Dense( units = 256, activation = tf.nn.leaky_relu)(pool3_flat )\n",
        "  drop4 = keras.layers.Dropout( rate = 0.4 )(dense4)\n",
        "\n",
        "  logits = keras.layers.Dense(units = 10, activation = tf.nn.softmax)(drop4)\n",
        "\n",
        "  return keras.Model( inputs = inputs, outputs = logits )# inputs = inputs 에서 앞의 i는 소문자 i이고, parameter i 이다.  뒤의 I는 소문자 I이고 함수 상단 inputs = keras.Input으로 받은 Inputs이다.\n",
        "\n",
        "model1 = create_model_relu()\n",
        "model2 = create_model_leaky_relu()\n"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BXNxsdpHwQk5",
        "outputId": "ba2ae4dc-02d2-462a-dee0-632801fb7ac5"
      },
      "source": [
        "model1.summary"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Model.summary of <tensorflow.python.keras.engine.functional.Functional object at 0x7f12fd49fcd0>>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gAG9liCpxjTo",
        "outputId": "d0098cbb-6517-4472-913c-ed49428bf988"
      },
      "source": [
        "model1.summary()"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_9 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
            "_________________________________________________________________\n",
            "conv2d_23 (Conv2D)           (None, 28, 28, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_23 (MaxPooling (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_24 (Conv2D)           (None, 14, 14, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_24 (MaxPooling (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_25 (Conv2D)           (None, 7, 7, 128)         73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_25 (MaxPooling (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_7 (Flatten)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 256)               524544    \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 619,786\n",
            "Trainable params: 619,786\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05tOoEMkxk73",
        "outputId": "ab2a2cd7-5f7a-4891-e952-4b043c687562"
      },
      "source": [
        "model2.summary()"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_10 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
            "_________________________________________________________________\n",
            "conv2d_26 (Conv2D)           (None, 28, 28, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_26 (MaxPooling (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_27 (Conv2D)           (None, 14, 14, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_27 (MaxPooling (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_28 (Conv2D)           (None, 7, 7, 128)         73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_28 (MaxPooling (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_8 (Flatten)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 256)               524544    \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 619,786\n",
            "Trainable params: 619,786\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dX9QGuK1xoX1"
      },
      "source": [
        "## 5. Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0hUXqgbGxutY",
        "outputId": "459bd44e-6f9a-4fd2-fefc-07724b0aaaa7"
      },
      "source": [
        "# make CNN Model Structure and Compile\n",
        "model1.compile( \n",
        "    loss = 'categorical_crossentropy', # cross entropy loss\n",
        "    optimizer = 'adam', # adam optimizer\n",
        "    metrics = ['accuracy']# 정확도 측정\n",
        ")\n",
        "\n",
        "# Execute Learning\n",
        "model1.fit(\n",
        "    train_images, train_labels, \n",
        "    batch_size = my_batch_size, # 2. Hyper Parameter 참고 , batch_size 는 조정가능 , 한번 학습할 때 얼마의 크기로 학습할 것인지\n",
        "    epochs = my_epochs, # 2. Hyper Parameter 참고, epochs 도 조정가능 , 몇번 학습할 것인지\n",
        "    verbose = 1, # verbose : 학습 중 출력 문구 설정( 아래 Epoch 1/15 600/600  어쩌구 나오는 이 문구들에 대한 설정 , verbose = 0 : silent , verbose = 1 : progress bar , verbose = 2 : one line per each epoch )\n",
        "    validation_data = (test_images, test_labels)\n",
        ")\n",
        "\n",
        "score = model1.evaluate(test_images, test_labels, verbose = 0)# check test result\n",
        "print('Test loss :', score[0] )\n",
        "print('Test accuracy :', score[1])"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "600/600 [==============================] - 86s 142ms/step - loss: 0.1932 - accuracy: 0.9380 - val_loss: 0.0458 - val_accuracy: 0.9839\n",
            "Epoch 2/15\n",
            "600/600 [==============================] - 85s 141ms/step - loss: 0.0551 - accuracy: 0.9839 - val_loss: 0.0339 - val_accuracy: 0.9894\n",
            "Epoch 3/15\n",
            "600/600 [==============================] - 84s 140ms/step - loss: 0.0388 - accuracy: 0.9877 - val_loss: 0.0310 - val_accuracy: 0.9908\n",
            "Epoch 4/15\n",
            "600/600 [==============================] - 84s 141ms/step - loss: 0.0297 - accuracy: 0.9909 - val_loss: 0.0231 - val_accuracy: 0.9927\n",
            "Epoch 5/15\n",
            "600/600 [==============================] - 84s 140ms/step - loss: 0.0242 - accuracy: 0.9924 - val_loss: 0.0233 - val_accuracy: 0.9923\n",
            "Epoch 6/15\n",
            "600/600 [==============================] - 84s 140ms/step - loss: 0.0216 - accuracy: 0.9934 - val_loss: 0.0256 - val_accuracy: 0.9911\n",
            "Epoch 7/15\n",
            "600/600 [==============================] - 84s 140ms/step - loss: 0.0179 - accuracy: 0.9945 - val_loss: 0.0217 - val_accuracy: 0.9916\n",
            "Epoch 8/15\n",
            "600/600 [==============================] - 84s 140ms/step - loss: 0.0152 - accuracy: 0.9950 - val_loss: 0.0242 - val_accuracy: 0.9924\n",
            "Epoch 9/15\n",
            "600/600 [==============================] - 84s 139ms/step - loss: 0.0123 - accuracy: 0.9960 - val_loss: 0.0269 - val_accuracy: 0.9917\n",
            "Epoch 10/15\n",
            "600/600 [==============================] - 83s 139ms/step - loss: 0.0111 - accuracy: 0.9963 - val_loss: 0.0256 - val_accuracy: 0.9927\n",
            "Epoch 11/15\n",
            "600/600 [==============================] - 84s 140ms/step - loss: 0.0106 - accuracy: 0.9969 - val_loss: 0.0239 - val_accuracy: 0.9933\n",
            "Epoch 12/15\n",
            "600/600 [==============================] - 84s 139ms/step - loss: 0.0121 - accuracy: 0.9958 - val_loss: 0.0266 - val_accuracy: 0.9920\n",
            "Epoch 13/15\n",
            "600/600 [==============================] - 84s 140ms/step - loss: 0.0084 - accuracy: 0.9970 - val_loss: 0.0255 - val_accuracy: 0.9930\n",
            "Epoch 14/15\n",
            "600/600 [==============================] - 84s 140ms/step - loss: 0.0073 - accuracy: 0.9976 - val_loss: 0.0219 - val_accuracy: 0.9931\n",
            "Epoch 15/15\n",
            "600/600 [==============================] - 84s 140ms/step - loss: 0.0079 - accuracy: 0.9976 - val_loss: 0.0200 - val_accuracy: 0.9941\n",
            "Test loss : 0.020008884370326996\n",
            "Test accuracy : 0.9940999746322632\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yq8V1-x4zMyo"
      },
      "source": [
        "# make CNN Model Structure and Compile\n",
        "model2.compile( \n",
        "    loss = 'categorical_crossentropy', # cross entropy loss\n",
        "    optimizer = 'adam', # adam optimizer\n",
        "    metrics = ['accuracy']# 정확도 측정\n",
        ")\n",
        "\n",
        "# Execute Learning\n",
        "model2.fit(\n",
        "    train_images, train_labels, \n",
        "    batch_size = my_batch_size, # 2. Hyper Parameter 참고 , batch_size 는 조정가능 , 한번 학습할 때 얼마의 크기로 학습할 것인지\n",
        "    epochs = my_epochs, # 2. Hyper Parameter 참고, epochs 도 조정가능 , 몇번 학습할 것인지\n",
        "    verbose = 1, # verbose : 학습 중 출력 문구 설정( 아래 Epoch 1/15 600/600  어쩌구 나오는 이 문구들에 대한 설정 , verbose = 0 : silent , verbose = 1 : progress bar , verbose = 2 : one line per each epoch )\n",
        "    validation_data = (test_images, test_labels)\n",
        ")\n",
        "\n",
        "score = model2.evaluate(test_images, test_labels, verbose = 0)# check test result\n",
        "print('Test loss :', score[0] )\n",
        "print('Test accuracy :', score[1])"
      ],
      "execution_count": 52,
      "outputs": []
    }
  ]
}