{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "text_Tokenize.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMQOw1QOMs6VOnWU6UEd5k2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JeongHanJun/Colab/blob/master/text_Tokenize.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cUwYFXUPlMB",
        "outputId": "152993fc-e182-445a-ec31-8e47528d000b"
      },
      "source": [
        "# 아래 2줄을 실행하지 않고 그 아래 셀을 실행하면 오류가 뜸.\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iof3wlSVPeT-",
        "outputId": "6361d9f8-78dc-45b0-dd83-f97e47a31f33"
      },
      "source": [
        "from nltk import sent_tokenize\n",
        "text_sample = 'The Matrix is everywhere its all around us, here even in this room. You can see it out your window or on your television. You feel it when you go to work, or go to church or pay your taxes.'\n",
        "tokenized_sentences = sent_tokenize(text_sample)\n",
        "print(tokenized_sentences)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['The Matrix is everywhere its all around us, here even in this room.', 'You can see it out your window or on your television.', 'You feel it when you go to work, or go to church or pay your taxes.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M90ICBcUPfF3",
        "outputId": "013f02c3-7f31-4e8f-bf35-11035485a900"
      },
      "source": [
        "text_sample = 'I am actively looking for Ph.D. students. and you are a Ph.D student.'\n",
        "tokenized_sentences = sent_tokenize(text_sample)\n",
        "print(tokenized_sentences)\n",
        "# 마침표를 기준으로 분리하지 않음"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['I am actively looking for Ph.D. students.', 'and you are a Ph.D student.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BcQWcspTP8AQ",
        "outputId": "84620ebb-8b31-42b7-dacc-f2207ba2efde"
      },
      "source": [
        "from nltk import word_tokenize\n",
        "text_sample = 'The Matrix is everywhere its all around us, here even in this room.'\n",
        "tokenized_words = word_tokenize(text_sample)\n",
        "print(tokenized_words)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['The', 'Matrix', 'is', 'everywhere', 'its', 'all', 'around', 'us', ',', 'here', 'even', 'in', 'this', 'room', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3l5HLhUQpb_",
        "outputId": "4caca6c3-1dbe-42c5-9777-efa627626586"
      },
      "source": [
        "text_sample = \"Don't be fooled by the dark sounding name, Mr. Jone's Orphanage is as cheery as cheery goes for a pastry shop.\"\n",
        "tokenized_words = word_tokenize(text_sample)\n",
        "print(tokenized_words)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Do', \"n't\", 'be', 'fooled', 'by', 'the', 'dark', 'sounding', 'name', ',', 'Mr.', 'Jone', \"'s\", 'Orphanage', 'is', 'as', 'cheery', 'as', 'cheery', 'goes', 'for', 'a', 'pastry', 'shop', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Ac-wgnKQ5MN",
        "outputId": "777f01fe-28df-46d2-d584-1c80b57110d9"
      },
      "source": [
        "from nltk.tokenize import WordPunctTokenizer\n",
        "text_sample = \"Don't be fooled by the dark sounding name, Mr. Jone's Orphanage is as cheery as cheery goes for a pastry shop.\"\n",
        "tokenized_words = WordPunctTokenizer().tokenize(text_sample)\n",
        "tokenized_words"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Don',\n",
              " \"'\",\n",
              " 't',\n",
              " 'be',\n",
              " 'fooled',\n",
              " 'by',\n",
              " 'the',\n",
              " 'dark',\n",
              " 'sounding',\n",
              " 'name',\n",
              " ',',\n",
              " 'Mr',\n",
              " '.',\n",
              " 'Jone',\n",
              " \"'\",\n",
              " 's',\n",
              " 'Orphanage',\n",
              " 'is',\n",
              " 'as',\n",
              " 'cheery',\n",
              " 'as',\n",
              " 'cheery',\n",
              " 'goes',\n",
              " 'for',\n",
              " 'a',\n",
              " 'pastry',\n",
              " 'shop',\n",
              " '.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohVNiMJlRJez",
        "outputId": "75cf1e10-f76d-4ecb-ecb4-40dd80bad271"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
        "text_sample = \"Don't be fooled by the dark sounding name, Mr. Jone's Orphanage is as cheery as cheery goes for a pastry shop.\"\n",
        "tokenized_words = text_to_word_sequence(text_sample)\n",
        "tokenized_words"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"don't\",\n",
              " 'be',\n",
              " 'fooled',\n",
              " 'by',\n",
              " 'the',\n",
              " 'dark',\n",
              " 'sounding',\n",
              " 'name',\n",
              " 'mr',\n",
              " \"jone's\",\n",
              " 'orphanage',\n",
              " 'is',\n",
              " 'as',\n",
              " 'cheery',\n",
              " 'as',\n",
              " 'cheery',\n",
              " 'goes',\n",
              " 'for',\n",
              " 'a',\n",
              " 'pastry',\n",
              " 'shop']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00VId-XmRlgp"
      },
      "source": [
        "## Keras 의 text_to_word_sequence 는 알파벳을 모두 소문자로 바꾸고, 구두점( 마침표, 쉼표 )는 없애고, 어퍼스트로피(`)는 보존한다."
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NzNnTthYSPiH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}