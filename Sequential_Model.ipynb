{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sequential Model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMvh16szMlkWSXD4dJQsNEz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JeongHanJun/Colab/blob/master/Sequential_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KvFSFm5_jbuA"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1U2hvZJkaxL"
      },
      "source": [
        "# 순차 모델을 사용하는 경우\n",
        "- 말그대로 순차 모델(Sequential Model) 이기 때문에, layer들을 스택으로 쌓는 경우에 적합하다.\n",
        "- 입력과 출력이 텐서로 같은 경우"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1Zn5nZnjpfb"
      },
      "source": [
        "hj_model = keras.Sequential(\n",
        "    [\n",
        "     layers.Dense(2, activation = 'relu', name = 'layer1 with relu'),\n",
        "     layers.Dense(3, activation = 'relu', name = 'layer2 with relu'),\n",
        "     layers.Dense(4, name = 'layer3 without Activation Function')\n",
        "    ]\n",
        ")# 모델 생성자에 Layers 입력하여 모델 생성 , 해당 레이어들은 'hj_model.layers'로 조회 가능\n",
        "\n",
        "# 모델에 layer 추가\n",
        "hj_model.add(layers.Dense(2, activation = 'relu'))\n",
        "#모델에 레이어를 제거\n",
        "hj_model.pop()\n",
        "x = tf.ones( (3, 3) )\n",
        "y = hj_model(x)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8CWeXsAJkAyq",
        "outputId": "14e06206-f8da-4044-f46f-825e9df327d9"
      },
      "source": [
        "x"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
              "array([[1., 1., 1.],\n",
              "       [1., 1., 1.],\n",
              "       [1., 1., 1.]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RiopWjTjkLZ2",
        "outputId": "fcd7d147-4b56-4aa9-dd65-87313cb1a36e"
      },
      "source": [
        "y"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 4), dtype=float32, numpy=\n",
              "array([[-0.5403077 ,  0.342919  ,  0.5274871 ,  0.16128561],\n",
              "       [-0.5403077 ,  0.342919  ,  0.5274871 ,  0.16128561],\n",
              "       [-0.5403077 ,  0.342919  ,  0.5274871 ,  0.16128561]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1M9YTWpUkMEN"
      },
      "source": [
        "# 순차 모델이 적합하지 않은 경우\n",
        "- 모델에 입력 또는 출력이 다중으로 존재할때 ( Multiple Input/Output in Model)\n",
        "- 모든 레이어에 입력 또는 출력이 다중으로 존재할때( Multiple Input/Output in layers)\n",
        "- 레이어 공유를 해야 하는 경우\n",
        "- 비선형 토폴로지를 하는 경우 ( residual connectionn, multiple branch model)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c44pe51ulofW",
        "outputId": "ae618c7a-8221-4270-ed7a-b4df25a5071d"
      },
      "source": [
        "hj_model.summary()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "layer1 with relu (Dense)     multiple                  8         \n",
            "_________________________________________________________________\n",
            "layer2 with relu (Dense)     multiple                  9         \n",
            "_________________________________________________________________\n",
            "layer3 without Activation Fu multiple                  16        \n",
            "=================================================================\n",
            "Total params: 33\n",
            "Trainable params: 33\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aL-InSqUuOAu"
      },
      "source": [
        "model = keras.Sequential()\n",
        "model.add(keras.Input(shape = (4,)))\n",
        "model.add(layers.Dense(2, activation = 'relu'))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GgVTqlVPuaXx",
        "outputId": "6e9b15fe-9143-40a2-c21e-7f7bbaedb2c8"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 2)                 10        \n",
            "=================================================================\n",
            "Total params: 10\n",
            "Trainable params: 10\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JIYPhRnmubTS",
        "outputId": "fa4b3716-e7d5-4dfe-fd18-91b2a5568580"
      },
      "source": [
        "model.layers"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<keras.layers.core.Dense at 0x7fb062252450>]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-NbIAsx2uiHG",
        "outputId": "0a96fcab-e802-46c1-8943-34557f1983f8"
      },
      "source": [
        "model = keras.Sequential()\n",
        "model.add(layers.Dense(2, activation = 'relu', input_shape = (4,)))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_2 (Dense)              (None, 2)                 10        \n",
            "=================================================================\n",
            "Total params: 10\n",
            "Trainable params: 10\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hv1KL6F6uukB"
      },
      "source": [
        "# 위 까지는 개념 설명이고, 실제로 모델을 어떻게 구성할 것인가?\n",
        "- 일반적으로, add() 로 layer를 쌓고, summary()로 확인한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iDI51rqUu58N",
        "outputId": "9e4c91c3-c6af-4061-8959-6e1de10ef765"
      },
      "source": [
        "model = keras.Sequential()\n",
        "model.add(keras.Input(shape = (250, 250, 3)))\n",
        "model.add(layers.Conv2D(32, 5, strides = 2, activation = 'relu'))\n",
        "model.add(layers.Conv2D(32, 3, activation = 'relu'))\n",
        "model.add(layers.MaxPooling2D(3))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 123, 123, 32)      2432      \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 121, 121, 32)      9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 40, 40, 32)        0         \n",
            "=================================================================\n",
            "Total params: 11,680\n",
            "Trainable params: 11,680\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k77D16UjvJmV",
        "outputId": "e59e5438-ecd1-4fb3-a1af-38a12a968c58"
      },
      "source": [
        "# 2개의 Layer를 쌓고, 1번의 Pooling , 이것은 일반적인 Sequential 모델의 아키텍쳐이다. 보통 이를 2~3번 반복하여 사용한다.\n",
        "# 추가적으로 모델 내부에서는 relu, 마지막 출력적에서는 softmax 를 activation func로 사용한다.\n",
        "model.add(layers.Conv2D(32, 3, activation = 'relu'))\n",
        "model.add(layers.Conv2D(32, 3, activation = 'relu'))\n",
        "model.add(layers.MaxPooling2D(3))\n",
        "\n",
        "model.add(layers.Conv2D(32, 3, activation = 'relu'))\n",
        "model.add(layers.Conv2D(32, 3, activation = 'relu'))\n",
        "model.add(layers.MaxPooling2D(2))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 123, 123, 32)      2432      \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 121, 121, 32)      9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 40, 40, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 38, 38, 32)        9248      \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 36, 36, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 10, 10, 32)        9248      \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 8, 8, 32)          9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 32)          0         \n",
            "=================================================================\n",
            "Total params: 48,672\n",
            "Trainable params: 48,672\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "As0AEgewwjrq"
      },
      "source": [
        "# 순차 모델을 사용한 특징 추출 ( Feature Selection wuth Sequential Model )"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VugZvEMRwsJ8"
      },
      "source": [
        "model_1 = keras.Sequential(\n",
        "    [\n",
        "     keras.Input(shape = (250, 250, 3)),\n",
        "     layers.Conv2D(32, 5, strides = 2, activation = 'relu'),\n",
        "     layers.Conv2D(32, 5, activation = 'relu'),\n",
        "     layers.Conv2D(32, 3, activation = 'relu')\n",
        "    ]\n",
        ")\n",
        "\n",
        "feature_extractor = keras.Model(\n",
        "    inputs = model_1.inputs,\n",
        "    outputs = [layer.output for layer in model_1.layers]\n",
        ")\n",
        "\n",
        "x = tf.ones((1, 250, 250, 3))\n",
        "features = feature_extractor(x)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6eVB1ApsxK9b",
        "outputId": "4753a066-301c-43ef-b079-da770c36d962"
      },
      "source": [
        "features"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Tensor: shape=(1, 123, 123, 32), dtype=float32, numpy=\n",
              " array([[[[0.        , 0.00929523, 0.00175618, ..., 0.09654894,\n",
              "           0.29414874, 0.        ],\n",
              "          [0.        , 0.00929523, 0.00175618, ..., 0.09654894,\n",
              "           0.29414874, 0.        ],\n",
              "          [0.        , 0.00929523, 0.00175618, ..., 0.09654894,\n",
              "           0.29414874, 0.        ],\n",
              "          ...,\n",
              "          [0.        , 0.00929523, 0.00175618, ..., 0.09654894,\n",
              "           0.29414874, 0.        ],\n",
              "          [0.        , 0.00929523, 0.00175618, ..., 0.09654894,\n",
              "           0.29414874, 0.        ],\n",
              "          [0.        , 0.00929523, 0.00175618, ..., 0.09654894,\n",
              "           0.29414874, 0.        ]],\n",
              " \n",
              "         [[0.        , 0.00929523, 0.00175618, ..., 0.09654894,\n",
              "           0.29414874, 0.        ],\n",
              "          [0.        , 0.00929523, 0.00175618, ..., 0.09654894,\n",
              "           0.29414874, 0.        ],\n",
              "          [0.        , 0.00929523, 0.00175618, ..., 0.09654894,\n",
              "           0.29414874, 0.        ],\n",
              "          ...,\n",
              "          [0.        , 0.00929523, 0.00175618, ..., 0.09654894,\n",
              "           0.29414874, 0.        ],\n",
              "          [0.        , 0.00929523, 0.00175618, ..., 0.09654894,\n",
              "           0.29414874, 0.        ],\n",
              "          [0.        , 0.00929523, 0.00175618, ..., 0.09654894,\n",
              "           0.29414874, 0.        ]],\n",
              " \n",
              "         [[0.        , 0.00929523, 0.00175618, ..., 0.09654894,\n",
              "           0.29414874, 0.        ],\n",
              "          [0.        , 0.00929523, 0.00175618, ..., 0.09654894,\n",
              "           0.29414874, 0.        ],\n",
              "          [0.        , 0.00929523, 0.00175618, ..., 0.09654894,\n",
              "           0.29414874, 0.        ],\n",
              "          ...,\n",
              "          [0.        , 0.00929523, 0.00175618, ..., 0.09654894,\n",
              "           0.29414874, 0.        ],\n",
              "          [0.        , 0.00929523, 0.00175618, ..., 0.09654894,\n",
              "           0.29414874, 0.        ],\n",
              "          [0.        , 0.00929523, 0.00175618, ..., 0.09654894,\n",
              "           0.29414874, 0.        ]],\n",
              " \n",
              "         ...,\n",
              " \n",
              "         [[0.        , 0.00929523, 0.00175618, ..., 0.09654894,\n",
              "           0.29414874, 0.        ],\n",
              "          [0.        , 0.00929523, 0.00175618, ..., 0.09654894,\n",
              "           0.29414874, 0.        ],\n",
              "          [0.        , 0.00929523, 0.00175618, ..., 0.09654894,\n",
              "           0.29414874, 0.        ],\n",
              "          ...,\n",
              "          [0.        , 0.00929523, 0.00175618, ..., 0.09654894,\n",
              "           0.29414874, 0.        ],\n",
              "          [0.        , 0.00929523, 0.00175618, ..., 0.09654894,\n",
              "           0.29414874, 0.        ],\n",
              "          [0.        , 0.00929523, 0.00175618, ..., 0.09654894,\n",
              "           0.29414874, 0.        ]],\n",
              " \n",
              "         [[0.        , 0.00929523, 0.00175618, ..., 0.09654894,\n",
              "           0.29414874, 0.        ],\n",
              "          [0.        , 0.00929523, 0.00175618, ..., 0.09654894,\n",
              "           0.29414874, 0.        ],\n",
              "          [0.        , 0.00929523, 0.00175618, ..., 0.09654894,\n",
              "           0.29414874, 0.        ],\n",
              "          ...,\n",
              "          [0.        , 0.00929523, 0.00175618, ..., 0.09654894,\n",
              "           0.29414874, 0.        ],\n",
              "          [0.        , 0.00929523, 0.00175618, ..., 0.09654894,\n",
              "           0.29414874, 0.        ],\n",
              "          [0.        , 0.00929523, 0.00175618, ..., 0.09654894,\n",
              "           0.29414874, 0.        ]],\n",
              " \n",
              "         [[0.        , 0.00929523, 0.00175618, ..., 0.09654894,\n",
              "           0.29414874, 0.        ],\n",
              "          [0.        , 0.00929523, 0.00175618, ..., 0.09654894,\n",
              "           0.29414874, 0.        ],\n",
              "          [0.        , 0.00929523, 0.00175618, ..., 0.09654894,\n",
              "           0.29414874, 0.        ],\n",
              "          ...,\n",
              "          [0.        , 0.00929522, 0.00175614, ..., 0.09654892,\n",
              "           0.2941488 , 0.        ],\n",
              "          [0.        , 0.00929522, 0.00175614, ..., 0.09654892,\n",
              "           0.2941488 , 0.        ],\n",
              "          [0.        , 0.00929522, 0.00175614, ..., 0.09654892,\n",
              "           0.2941488 , 0.        ]]]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(1, 119, 119, 32), dtype=float32, numpy=\n",
              " array([[[[0.        , 0.03221281, 0.        , ..., 0.        ,\n",
              "           0.10055228, 0.        ],\n",
              "          [0.        , 0.03221281, 0.        , ..., 0.        ,\n",
              "           0.10055228, 0.        ],\n",
              "          [0.        , 0.03221281, 0.        , ..., 0.        ,\n",
              "           0.10055228, 0.        ],\n",
              "          ...,\n",
              "          [0.        , 0.03221281, 0.        , ..., 0.        ,\n",
              "           0.10055228, 0.        ],\n",
              "          [0.        , 0.03221281, 0.        , ..., 0.        ,\n",
              "           0.10055228, 0.        ],\n",
              "          [0.        , 0.03221281, 0.        , ..., 0.        ,\n",
              "           0.10055228, 0.        ]],\n",
              " \n",
              "         [[0.        , 0.03221281, 0.        , ..., 0.        ,\n",
              "           0.10055228, 0.        ],\n",
              "          [0.        , 0.03221281, 0.        , ..., 0.        ,\n",
              "           0.10055228, 0.        ],\n",
              "          [0.        , 0.03221281, 0.        , ..., 0.        ,\n",
              "           0.10055228, 0.        ],\n",
              "          ...,\n",
              "          [0.        , 0.03221281, 0.        , ..., 0.        ,\n",
              "           0.10055228, 0.        ],\n",
              "          [0.        , 0.03221281, 0.        , ..., 0.        ,\n",
              "           0.10055228, 0.        ],\n",
              "          [0.        , 0.03221281, 0.        , ..., 0.        ,\n",
              "           0.10055228, 0.        ]],\n",
              " \n",
              "         [[0.        , 0.03221281, 0.        , ..., 0.        ,\n",
              "           0.10055228, 0.        ],\n",
              "          [0.        , 0.03221281, 0.        , ..., 0.        ,\n",
              "           0.10055228, 0.        ],\n",
              "          [0.        , 0.03221281, 0.        , ..., 0.        ,\n",
              "           0.10055228, 0.        ],\n",
              "          ...,\n",
              "          [0.        , 0.03221281, 0.        , ..., 0.        ,\n",
              "           0.10055228, 0.        ],\n",
              "          [0.        , 0.03221281, 0.        , ..., 0.        ,\n",
              "           0.10055228, 0.        ],\n",
              "          [0.        , 0.03221281, 0.        , ..., 0.        ,\n",
              "           0.10055228, 0.        ]],\n",
              " \n",
              "         ...,\n",
              " \n",
              "         [[0.        , 0.03221281, 0.        , ..., 0.        ,\n",
              "           0.10055228, 0.        ],\n",
              "          [0.        , 0.03221281, 0.        , ..., 0.        ,\n",
              "           0.10055228, 0.        ],\n",
              "          [0.        , 0.03221281, 0.        , ..., 0.        ,\n",
              "           0.10055228, 0.        ],\n",
              "          ...,\n",
              "          [0.        , 0.03221281, 0.        , ..., 0.        ,\n",
              "           0.10055228, 0.        ],\n",
              "          [0.        , 0.03221281, 0.        , ..., 0.        ,\n",
              "           0.10055228, 0.        ],\n",
              "          [0.        , 0.03221281, 0.        , ..., 0.        ,\n",
              "           0.10055228, 0.        ]],\n",
              " \n",
              "         [[0.        , 0.03221281, 0.        , ..., 0.        ,\n",
              "           0.10055228, 0.        ],\n",
              "          [0.        , 0.03221281, 0.        , ..., 0.        ,\n",
              "           0.10055228, 0.        ],\n",
              "          [0.        , 0.03221281, 0.        , ..., 0.        ,\n",
              "           0.10055228, 0.        ],\n",
              "          ...,\n",
              "          [0.        , 0.03221281, 0.        , ..., 0.        ,\n",
              "           0.10055228, 0.        ],\n",
              "          [0.        , 0.03221281, 0.        , ..., 0.        ,\n",
              "           0.10055228, 0.        ],\n",
              "          [0.        , 0.03221281, 0.        , ..., 0.        ,\n",
              "           0.10055228, 0.        ]],\n",
              " \n",
              "         [[0.        , 0.03221281, 0.        , ..., 0.        ,\n",
              "           0.10055228, 0.        ],\n",
              "          [0.        , 0.03221281, 0.        , ..., 0.        ,\n",
              "           0.10055228, 0.        ],\n",
              "          [0.        , 0.03221281, 0.        , ..., 0.        ,\n",
              "           0.10055228, 0.        ],\n",
              "          ...,\n",
              "          [0.        , 0.0322128 , 0.        , ..., 0.        ,\n",
              "           0.10055226, 0.        ],\n",
              "          [0.        , 0.03221279, 0.        , ..., 0.        ,\n",
              "           0.10055228, 0.        ],\n",
              "          [0.        , 0.03221276, 0.        , ..., 0.        ,\n",
              "           0.10055228, 0.        ]]]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(1, 117, 117, 32), dtype=float32, numpy=\n",
              " array([[[[0.29578352, 0.        , 0.        , ..., 0.29277575,\n",
              "           0.02838636, 0.        ],\n",
              "          [0.29578352, 0.        , 0.        , ..., 0.29277575,\n",
              "           0.02838636, 0.        ],\n",
              "          [0.29578352, 0.        , 0.        , ..., 0.29277575,\n",
              "           0.02838636, 0.        ],\n",
              "          ...,\n",
              "          [0.29578352, 0.        , 0.        , ..., 0.29277575,\n",
              "           0.02838636, 0.        ],\n",
              "          [0.29578352, 0.        , 0.        , ..., 0.29277575,\n",
              "           0.02838636, 0.        ],\n",
              "          [0.29578352, 0.        , 0.        , ..., 0.29277575,\n",
              "           0.02838636, 0.        ]],\n",
              " \n",
              "         [[0.29578352, 0.        , 0.        , ..., 0.29277575,\n",
              "           0.02838636, 0.        ],\n",
              "          [0.29578352, 0.        , 0.        , ..., 0.29277575,\n",
              "           0.02838636, 0.        ],\n",
              "          [0.29578352, 0.        , 0.        , ..., 0.29277575,\n",
              "           0.02838636, 0.        ],\n",
              "          ...,\n",
              "          [0.29578352, 0.        , 0.        , ..., 0.29277575,\n",
              "           0.02838636, 0.        ],\n",
              "          [0.29578352, 0.        , 0.        , ..., 0.29277575,\n",
              "           0.02838636, 0.        ],\n",
              "          [0.29578352, 0.        , 0.        , ..., 0.29277575,\n",
              "           0.02838636, 0.        ]],\n",
              " \n",
              "         [[0.29578352, 0.        , 0.        , ..., 0.29277575,\n",
              "           0.02838636, 0.        ],\n",
              "          [0.29578352, 0.        , 0.        , ..., 0.29277575,\n",
              "           0.02838636, 0.        ],\n",
              "          [0.29578352, 0.        , 0.        , ..., 0.29277575,\n",
              "           0.02838636, 0.        ],\n",
              "          ...,\n",
              "          [0.29578352, 0.        , 0.        , ..., 0.29277575,\n",
              "           0.02838636, 0.        ],\n",
              "          [0.29578352, 0.        , 0.        , ..., 0.29277575,\n",
              "           0.02838636, 0.        ],\n",
              "          [0.29578352, 0.        , 0.        , ..., 0.29277575,\n",
              "           0.02838636, 0.        ]],\n",
              " \n",
              "         ...,\n",
              " \n",
              "         [[0.29578352, 0.        , 0.        , ..., 0.29277575,\n",
              "           0.02838636, 0.        ],\n",
              "          [0.29578352, 0.        , 0.        , ..., 0.29277575,\n",
              "           0.02838636, 0.        ],\n",
              "          [0.29578352, 0.        , 0.        , ..., 0.29277575,\n",
              "           0.02838636, 0.        ],\n",
              "          ...,\n",
              "          [0.29578352, 0.        , 0.        , ..., 0.29277575,\n",
              "           0.02838636, 0.        ],\n",
              "          [0.29578352, 0.        , 0.        , ..., 0.29277575,\n",
              "           0.02838636, 0.        ],\n",
              "          [0.29578352, 0.        , 0.        , ..., 0.29277575,\n",
              "           0.02838636, 0.        ]],\n",
              " \n",
              "         [[0.29578352, 0.        , 0.        , ..., 0.29277575,\n",
              "           0.02838636, 0.        ],\n",
              "          [0.29578352, 0.        , 0.        , ..., 0.29277575,\n",
              "           0.02838636, 0.        ],\n",
              "          [0.29578352, 0.        , 0.        , ..., 0.29277575,\n",
              "           0.02838636, 0.        ],\n",
              "          ...,\n",
              "          [0.29578352, 0.        , 0.        , ..., 0.29277575,\n",
              "           0.02838636, 0.        ],\n",
              "          [0.29578352, 0.        , 0.        , ..., 0.29277575,\n",
              "           0.02838636, 0.        ],\n",
              "          [0.29578352, 0.        , 0.        , ..., 0.29277575,\n",
              "           0.02838636, 0.        ]],\n",
              " \n",
              "         [[0.29578352, 0.        , 0.        , ..., 0.29277575,\n",
              "           0.02838636, 0.        ],\n",
              "          [0.29578352, 0.        , 0.        , ..., 0.29277575,\n",
              "           0.02838636, 0.        ],\n",
              "          [0.29578352, 0.        , 0.        , ..., 0.29277575,\n",
              "           0.02838636, 0.        ],\n",
              "          ...,\n",
              "          [0.29578346, 0.        , 0.        , ..., 0.29277575,\n",
              "           0.02838633, 0.        ],\n",
              "          [0.29578346, 0.        , 0.        , ..., 0.29277575,\n",
              "           0.02838637, 0.        ],\n",
              "          [0.29578346, 0.        , 0.        , ..., 0.29277578,\n",
              "           0.02838635, 0.        ]]]], dtype=float32)>]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWiS_eAQxY8X"
      },
      "source": [
        "model_2 = keras.Sequential(\n",
        "    [\n",
        "     keras.Input(shape = (250, 250, 3)),\n",
        "     layers.Conv2D(32, 5, strides = 2, activation = 'relu'),\n",
        "     layers.Conv2D(32, 3, activation = 'relu', name = 'my_intermediate_layer'),\n",
        "     layers.Conv2D(32, 3, activation = 'relu'),\n",
        "    ]\n",
        ")\n",
        "\n",
        "feature_extractor = keras.Model(\n",
        "    inputs = model_2.inputs,\n",
        "    outputs = model_2.get_layer(name = 'my_intermediate_layer').output\n",
        ")\n",
        "\n",
        "x = tf.ones( (1, 250, 250, 3) )\n",
        "features = feature_extractor(x)"
      ],
      "execution_count": 32,
      "outputs": []
    }
  ]
}